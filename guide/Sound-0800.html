<!DOCTYPE html>
<html>
<head>
	<title>Sound</title>
	<link href="./assets/style.css" rel="stylesheet" type="text/css" />
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
</head>

<body>
<div id="header">
  <div id="pts"><a href="../">Pts<span>.</span></a>guides</div>
  <div id="topmenu">
    <a href="../demo/index.html">demos</a>
    <a href="../study/index.html">studies</a>
    <a href="../docs/">docs</a>
    <a href="https://github.com/williamngan/pts">github</a>
  </div>
</div>
<a href="#menu" id="toc">&#x2261;</a>
<div id="post"><h1>Sound</h1>
<p>Audio and visual forms complement each other, giving us new opportunities to create unique expressions. Pts simplifies a subset of Web Audio API to help you with common tasks like playbacks and visualizations.</p>
<p>Before we dive in, let's review a snippet of using Pts' Sound functions. It's pretty straightforward.</p>
<pre><code>// Load sound and attach analyzer
Sound.load( &quot;/assets/spacetravel.mp3&quot; ).then( s =&gt; {
  sound = s.analyze(bins);
});

// ...

// Visualize frequencies (within animate loop)
sound.freqDomainTo( space.size ).forEach( (t, i) =&gt; {
  form.fill( colors[i%5] ).point( t, 30 );
});
</code></pre>
<p>Here is the result. Click play button to start.</p>
<p><img src="./assets/bg.png" alt="js:sound_simple"></p>
<h5>Music snippet from <a href="https://soundcloud.com/mrgreenh/space-travel-cliches"><em>Space Travel Clichés</em></a> by Mr Green H.</h5>
<p>How about something more elaborate? Let's try a silly and fun visualization.</p>
<p><img src="./assets/bg.png" alt="js:sound_visual"></p>
<h5>Click play button and move your pointer around the character. Music snippet from <a href="https://soundcloud.com/mrgreenh/space-travel-cliches"><em>Space Travel Clichés</em></a> by Mr Green H.</h5>
<h3>Input</h3>
<p>Let's get some sounds to begin! Do you want to load from a sound file, receive microphone input, or generate audio dynamically? Pts offers four handy static functions for these.</p>
<ol>
<li>Use <a href="#play-sound"><code>Sound.load</code></a> to load a sound file with an url or a specific <code>&lt;audio&gt;</code> element. The sound will play as soon as it has streamed enough data. You can check if the audio file is ready to play by accessing <a href="#play-sound"><code>.playable</code></a> property.</li>
</ol>
<pre><code>Sound.load( &quot;/path/to/hello.mp3&quot; ).then( s =&gt; sound = s );
Sound.load( audioElem ).then( s =&gt; sound = s ); // load from &lt;audio&gt; element
</code></pre>
<ol start="2">
<li>Use <a href="#play-sound"><code>Sound.loadAsBuffer</code></a> if you need support for Safari and iOS, since they currently don't provide sound data for &lt;audio&gt; element reliably. See discussion in Advanced section below.</li>
</ol>
<pre><code>Sound.loadAsBuffer( &quot;/path/to/hello.mp3&quot; ).then( s =&gt; sound = s );
</code></pre>
<ol start="3">
<li>Use <a href="#play-sound"><code>Sound.generate</code></a> to create a sound. You may also generate sounds using other libraries like Tone.js. Read more in Advanced section below.</li>
</ol>
<pre><code>let sound = Sound.generate( &quot;sine&quot;, 120 ); // sine oscillator at 120Hz
</code></pre>
<ol start="4">
<li>Use <a href="#play-sound"><code>Sound.input</code></a> to get audio from default input device (usually microphone). This will return a Promise object which will resolve when the input device is ready.</li>
</ol>
<pre><code>let sound;
Sound.input().then( s =&gt; sound = s ); // default input device
Sound.input( constraints ).then( s =&gt; sound = s ); // advanced use cases
</code></pre>
<p>Here's a basic demo of getting audio from microphone:</p>
<p><img src="./assets/bg.png" alt="js:sound_mic"></p>
<h5>You may first need to allow this page to access microphone, and then click the record button. We also make the recording stop when the pointer leave the demo area so that your microphone is not always on.</h5>
<p>You can then <a href="#play-sound"><code>start</code></a> and <a href="#play-sound"><code>stop</code></a> playing the sound like this:</p>
<pre><code>sound.start();
sound.stop();
sound.toggle(); // toggle between start and stop
sound.playing; // boolean to indicate if sound is playing
</code></pre>
<h5>Note that current browsers no longer support autoplay. Users will need to express intent to play the sound (eg, with a click).</h5>
<h3>Analyze</h3>
<p>Using the <a href="#play-sound"><code>analyze</code></a> function, we can attach an analyzer to keep track of the data in our Sound instance.</p>
<pre><code>sound.analyze( 128 ); // Call once to initiate the analyzer
</code></pre>
<p>This will create an analyzer with 128 bins (more on that later) and default decibel range and smoothing values. See <a href="#play-sound"><code>analyze</code></a> docs for description of the advanced options.</p>
<p>There are two common ways to analyze sound data. First, we can represent sounds as snapshots of sound waves, which correspond to variations in air pressure over time. This is called the time-domain, as it measures amplitudes of the &quot;waves&quot; over time steps.</p>
<p>To get the time domain data at current time step, call the <a href="#play-sound"><code>timeDomain</code></a> function.</p>
<pre><code>// get an uint typed array of 128 values (corresponds to bin size above)
let td = sound.timeDomain(); 
</code></pre>
<p>Optionaly, use the <a href="#play-sound"><code>timeDomainTo</code></a> function to map the data to another range, such as a rectangular area. You can then apply various Pts functions to transform and visualize waveforms in a few lines of code.</p>
<pre><code>// fit data into a 200x100 area, starting from position (50, 50)
let td = sound.timeDomainTo( [200, 100], [50, 50] );

form.points( td ); // visualize as points
</code></pre>
<p>In the following example, we map the data to a normalized circle and then re-map it to draw colorful lines.</p>
<pre><code>sound.timeDomainTo( [Const.two_pi, 1] ).map( t =&gt; ... );
</code></pre>
<p><img src="./assets/bg.png" alt="js:sound_time"></p>
<h5>Click to play and visualize sounds of drum, tambourine, and flute from Philharmonia Orchestra.</h5>
<p>In a similar way, we can access the frequency domain data by <a href="#play-sound"><code>freqDomain</code></a> and <a href="#play-sound"><code>freqDomainTo</code></a>. The frequency bins are calculated by an algorithm called Fast Fourier Transform (FFT). The FFT size is usually 2 times the bin size and they need to be multiples of 2. (Recall that we set bin size to 128 earlier). You can quickly test it with a single line of code:</p>
<pre><code>form.points( sound.freqDomainTo( space.size ) );
</code></pre>
<p>The following is a basic frequency-domain example for your reference.</p>
<p><img src="./assets/bg.png" alt="js:sound_frequency"></p>
<p>The interplay of sounds and shapes offer many possibilities indeed. Make good use of your imagination to create something beautiful, fun, and unexpected!</p>
<h3>Advanced</h3>
<p>Currently Safari and iOS can play streaming &lt;audio&gt; element, but don't reliably provide time and frequency domain data for it. Hopefully Safari will have a fix soon, but for now you can use <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a> approach - it's a bit more clumsy but it works (see <a href="#play-sound"><code>loadAsBuffer</code></a>).</p>
<pre><code>Sound.loadAsBuffer( &quot;/path/to/hello.mp3&quot; ).then( s =&gt; sound = s );
</code></pre>
<p><code>AudioBuffer</code> doesn't support streaming and can only be played once. To replay it, you need to recreate the buffer and reconnect the nodes. Use the convenient <a href="#play-sound"><code>createBuffer</code></a> function without parameter to re-use the previous buffer.</p>
<pre><code>// replay the sound by reusing previously loaded buffer
sound.createBuffer().analyze(bins);
</code></pre>
<p>For custom use cases with other libraries, you can create an instance using  <a href="#play-sound"><code>Sound.from</code></a> static method. Here's an example using Tone.js:</p>
<pre><code>let synth = new Tone.Synth(); 
let sound = Sound.from( synth, synth.context ); // create Pts Sound instance
synth.toMaster(); // play using tone.js instead of Pts
</code></pre>
<p>The following demo generates audio using <a href="https://tonejs.github.io/">Tone.js</a> and then visualizes it with Pts:</p>
<p><a href="./js/examples/tone.html"> <img src="./assets/tone.png" alt="screenshot"> </a></p>
<h5>Click image to open tone.js demo. See <a href="https://github.com/williamngan/pts/blob/master/guide/js/examples/tone.html">source code here</a>.</h5>
<p>If needed, you can also directly access the following properties in a Sound instance to make full use of the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a>.</p>
<ul>
<li><code>.ctx</code> to access the <code>AudioContext</code> instance</li>
<li><code>.node</code> to access the <code>AudioNode</code> instance</li>
<li><code>.stream</code> to access the <code>MediaStream</code> instance if applicable</li>
<li><code>.source</code> to access the <code>HTMLMediaElement</code> if you're playing from a sound file</li>
<li><code>.buffer</code> to access or set the <code>AudioBuffer</code> if you're using <a href="#play-sound"><code>loadAsBuffer</code></a></li>
</ul>
<p>Also note that calling <a href="#play-sound"><code>start</code></a> function will connect the AudioNode to the destination of the AudioContext, while <a href="#play-sound"><code>stop</code></a> will disconnect it.</p>
<p>Web Audio covers a wide range of topics. Here are a few pointers for you to dive deeper:</p>
<ul>
<li><a href="https://webaudioapi.com/book/">Web Audio API book</a> and <a href="https://webaudioapi.com/samples/">samples</a> by Boris Smus</li>
<li><a href="https://tonejs.github.io/">tone.js</a> is a framework for creating interactive music in the browser</li>
<li><a href="https://github.com/danigb/tonal">tonal.js</a> is a functional music theory library for javascript</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">MDN documentation</a> on Web Audio API</li>
</ul>
<h3>Cheatsheet</h3>
<p>Creating and playing a <a href="#play-sound"><code>Sound</code></a> instance</p>
<pre><code>Sound.load( &quot;path/file.mp3&quot; ).then( d =&gt; s = d ); // from file
Sound.loadAsBuffer( &quot;path/file.mp3&quot; ).then( d =&gt; s = d ); // using AudioBuffer instead
Sound.input().then( d =&gt; s = d ); // get microphone input
s = Sound.generate( &quot;sine&quot;, 120 ); // sine wave at 120hz
s = Sound.from( node, context ); // advanced use case

s.start();
s.stop();
s.toggle();
</code></pre>
<p>Getting time domain and frequency domain data</p>
<pre><code>s.analyzer( 256 ); // Create analyzer with 256 bins. Call once only.

s.timeDomain();
s.timeDomainTo( area, position ); // map to a area [w, h] from position [x, y]

s.freqDomain();
s.freqDomainTo( [10, 5] ); // map to a 10x5 area
</code></pre>
</div>

<ol id="menu"><a id="close" href="#">&times;</a><li><a href="Get-started-0100.html">Get started</a></li><li><a href="Pt-0200.html">Pt</a></li><li><a href="Group-0300.html">Group</a></li><li><a href="Op-0400.html">Op</a></li><li><a href="Space-0500.html">Space</a></li><li><a href="Typography-0600.html">Typography</a></li><li><a href="Animation-0700.html">Animation</a></li><li><a href="Sound-0800.html">Sound</a></li><li><a href="Image-0900.html">Image</a></li><li><a href="Technical-notes-9000.html">Technical notes</a></li></ol>

<div id="footer">Copyright &copy; 2017-current by <a href="https://twitter.com/williamngan">William Ngan</a> and contributors. Pts is an <a href="https://github.com/williamngan/pts">open source project</a> under Apache License 2.0.</div>

<script type="text/javascript" src="../dist/pts.min.js"></script>
<script type="text/javascript" src="./js/guide.js"></script>
<script src="./js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-104913373-1', 'auto');
  ga('send', 'pageview');

</script>

</body>
</html>